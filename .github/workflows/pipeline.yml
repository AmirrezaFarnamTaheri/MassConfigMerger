name: Merge and Retest VPN Subscriptions

on:
  schedule:
    # Run every hour
    - cron: '0 * * * *'
  workflow_dispatch:
    inputs:
      force_merge:
        description: 'Force merge regardless of schedule'
        required: false
        default: 'false'
  push:
    paths:
      - 'sources.txt'
      - '.github/workflows/merge.yml'
      - 'src/**'

permissions:
  contents: write
  pages: write
  id-token: write
  actions: write

concurrency:
  group: merge-pipeline
  cancel-in-progress: false

jobs:
  # ========================================================================
  # STEP 1: Determine Job Type & Acquire Lock
  # ========================================================================
  prepare:
    name: Prepare - Determine Job Type
    runs-on: ubuntu-latest
    outputs:
      job-type: ${{ steps.determine.outputs.job_type }}
      should-run: ${{ steps.determine.outputs.should_run }}

    steps:
      - name: Determine which job should run
        id: determine
        run: |
          hour=$(date -u +%H)
          force_merge="${{ github.event.inputs.force_merge }}"

          # Check if this is a manual trigger with force_merge
          if [[ "$force_merge" == "true" ]]; then
            job_type="merge"
            should_run="true"
            echo "🔧 Manual trigger: forcing merge job"
          # Merge at 0, 3, 6, 9, 12, 15, 18, 21 UTC
          elif [ $((hour % 3)) -eq 0 ]; then
            job_type="merge"
            should_run="true"
            echo "🔄 Scheduled merge job at hour $hour"
          else
            job_type="retest"
            should_run="true"
            echo "🔍 Scheduled retest job at hour $hour"
          fi

          echo "job_type=${job_type}" >> $GITHUB_OUTPUT
          echo "should_run=${should_run}" >> $GITHUB_OUTPUT

  # ========================================================================
  # STEP 2: Merge Job (Every 3 Hours)
  # ========================================================================
  merge-configs:
    name: Merge Proxy Configurations
    needs: prepare
    if: needs.prepare.outputs.job-type == 'merge' && needs.prepare.outputs.should-run == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 50

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.cache/pip
            ~/.local
          key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml', '**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y geoip-bin geoipupdate curl wget

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e .
          pip list  # Log installed packages for debugging

      - name: Create output directory
        run: |
          mkdir -p output
          chmod 755 output

          # Create initial empty files if they don't exist
          if [ ! -f output/proxies.json ]; then
            echo "[]" > output/proxies.json
          fi
          if [ ! -f output/statistics.json ]; then
            echo '{"total_tested": 0, "working": 0, "failed": 0, "success_rate": 0}' > output/statistics.json
          fi

      - name: Cache GeoIP databases
        id: cache-geoip
        uses: actions/cache@v3
        with:
          path: |
            data/*.mmdb
          key: geoip-${{ runner.os }}-${{ hashFiles('data/*.mmdb.version') }}
          restore-keys: |
            geoip-${{ runner.os }}-

      - name: Download GeoIP databases
        if: steps.cache-geoip.outputs.cache-hit != 'true'
        env:
          MAXMIND_LICENSE_KEY: ${{ secrets.MAXMIND_LICENSE_KEY }}
        run: |
          if [ -z "$MAXMIND_LICENSE_KEY" ]; then
            echo "⚠️  MAXMIND_LICENSE_KEY not set - GeoIP features disabled"
            echo "To enable: Add MAXMIND_LICENSE_KEY to repository secrets"
          else
            echo "📥 Downloading fresh GeoIP databases..."
            configstream update-databases
            # Create version file for cache key
            date +%Y%m%d > data/geoip.mmdb.version
            echo "✅ GeoIP databases updated"
          fi

      - name: Run merge pipeline
        id: merge
        env:
          PYTHONUNBUFFERED: 1
          LOG_LEVEL: INFO
        run: |
          echo "🚀 Starting merge pipeline..."

          # Run with detailed error output
          configstream merge \
            --sources sources.txt \
            --output output/ \
            --max-workers 25 \
            --timeout 10 \
            --verbose \
          || exit_code=$?

          if [ "${exit_code:-0}" -ne 0 ]; then
            echo "❌ Merge pipeline failed with exit code: ${exit_code}"
            # Don't fail immediately, try to save partial results
          fi

          echo "merge_status=${exit_code:-0}" >> $GITHUB_OUTPUT

      - name: Validate output files
        id: validate
        run: |
          echo "📋 Validating output files..."
          validation_failed=false

          # Check required files exist
          for file in output/proxies.json output/statistics.json; do
            if [ ! -f "$file" ]; then
              echo "❌ Missing: $file"
              validation_failed=true
            else
              echo "✅ Found: $file"

              # Validate JSON syntax
              if python3 -m json.tool "$file" > /dev/null 2>&1; then
                echo "✅ Valid JSON: $file"
              else
                echo "❌ Invalid JSON: $file"
                validation_failed=true
              fi
            fi
          done

          # Check proxy count
          if [ -f "output/proxies.json" ]; then
            proxy_count=$(python3 -c "import json; print(len(json.load(open('output/proxies.json'))))" 2>/dev/null || echo "0")
            echo "📊 Proxy count: ${proxy_count}"

            if [ "$proxy_count" -eq "0" ]; then
              echo "⚠️ Warning: No proxies found!"
            fi

            echo "proxy_count=${proxy_count}" >> $GITHUB_OUTPUT
          fi

          if [ "$validation_failed" = true ]; then
            echo "validation_status=failed" >> $GITHUB_OUTPUT
            exit 1
          else
            echo "validation_status=passed" >> $GITHUB_OUTPUT
          fi

      - name: Generate enhanced metadata
        id: metadata
        run: |
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          CACHE_BUST=$(date +%s)
          PROXY_COUNT="${{ steps.validate.outputs.proxy_count }}"

          cat > output/metadata.json << EOF
          {
            "generated_at": "${TIMESTAMP}",
            "cache_bust": "${CACHE_BUST}",
            "version": "1.0.2",
            "job_type": "merge",
            "status": "success",
            "workflow_run_id": "${{ github.run_id }}",
            "workflow_run_url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}",
            "commit_sha": "${{ github.sha }}",
            "commit_short": "$(echo ${{ github.sha }} | cut -c1-7)",
            "proxy_count": ${PROXY_COUNT:-0},
            "github_actor": "${{ github.actor }}",
            "github_event": "${{ github.event_name }}"
          }
          EOF

          echo "✅ Metadata generated at ${TIMESTAMP}"
          cat output/metadata.json

      - name: Commit and push changes
        id: commit
        run: |
          git config --local user.name "github-actions[bot]"
          git config --local user.email "github-actions[bot]@users.noreply.github.com"

          # Add all output files
          git add output/

          # Check for changes
          if git diff --staged --quiet; then
            echo "ℹ️ No changes to commit"
            echo "status=no-changes" >> $GITHUB_OUTPUT
          else
            TIMESTAMP=$(date -u +'%Y-%m-%d %H:%M:%S UTC')
            PROXY_COUNT="${{ steps.validate.outputs.proxy_count }}"

            # Create detailed commit message
            git commit -m "🤖 Merge configs - ${TIMESTAMP}

Processed proxies: ${PROXY_COUNT}
Generated at: ${TIMESTAMP}
Workflow run: ${{ github.run_id }}
Event: ${{ github.event_name }}

[skip ci]"

            # Push with retry
            for i in {1..3}; do
              if git push origin main; then
                echo "✅ Changes pushed successfully"
                echo "status=pushed" >> $GITHUB_OUTPUT
                break
              else
                echo "⚠️ Push attempt $i failed, retrying..."
                sleep 5
              fi
            done
          fi

      - name: Trigger GitHub Pages deployment
        if: steps.commit.outputs.status == 'pushed'
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('🚀 Triggering GitHub Pages deployment...');

            try {
              // First, check if the workflow exists
              const workflows = await github.rest.actions.listWorkflowsForRepo({
                owner: context.repo.owner,
                repo: context.repo.repo
              });

              const deployWorkflow = workflows.data.workflows.find(w =>
                w.path === '.github/workflows/deploy-pages.yml'
              );

              if (deployWorkflow) {
                // Trigger the deployment
                await github.rest.actions.createWorkflowDispatch({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: deployWorkflow.id,
                  ref: 'main'
                });
                console.log('✅ Deployment workflow triggered successfully');
              } else {
                console.log('⚠️ Deploy workflow not found, Pages will update automatically');
              }
            } catch (error) {
              console.warn('⚠️ Could not trigger deployment:', error.message);
              console.log('Pages will update automatically on next push');
            }

      - name: Upload artifacts for debugging
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: merge-output-${{ github.run_id }}
          path: |
            output/
          retention-days: 7

      - name: Report final status
        if: always()
        run: |
          echo "## 📊 Merge Job Summary"
          echo "| Metric | Value |"
          echo "|--------|-------|"
          echo "| Job Status | ${{ job.status }} |"
          echo "| Merge Status | ${{ steps.merge.outputs.merge_status }} |"
          echo "| Validation | ${{ steps.validate.outputs.validation_status }} |"
          echo "| Proxies Found | ${{ steps.validate.outputs.proxy_count }} |"
          echo "| Changes | ${{ steps.commit.outputs.status }} |"
          echo "| Workflow | [${{ github.run_id }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) |"

  # ========================================================================
  # STEP 3: Retest Job (Every Hour When Not Merging)
  # ========================================================================
  retest-configs:
    name: Retest Existing Proxies
    needs: prepare
    if: needs.prepare.outputs.job-type == 'retest' && needs.prepare.outputs.should-run == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 35

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .

      - name: Check existing proxies
        id: check
        run: |
          if [ -f "output/proxies.json" ]; then
            proxy_count=$(python3 -c "import json; print(len(json.load(open('output/proxies.json'))))" 2>/dev/null || echo "0")
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "count=${proxy_count}" >> $GITHUB_OUTPUT
            echo "📊 Found ${proxy_count} existing proxies to retest"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "count=0" >> $GITHUB_OUTPUT
            echo "⚠️ No existing proxies found, skipping retest"
          fi

      - name: Run retest
        if: steps.check.outputs.exists == 'true' && steps.check.outputs.count != '0'
        run: |
          echo "🔄 Starting retest of existing proxies..."

          configstream retest \
            --input output/proxies.json \
            --output output/ \
            --max-workers 30 \
            --timeout 8 \
            --verbose

      - name: Update retest metadata
        if: steps.check.outputs.exists == 'true'
        run: |
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

          # Update only the retest timestamp in metadata
          python3 << 'EOF'
          import json
          from pathlib import Path

          metadata_file = Path('output/metadata.json')

          if metadata_file.exists():
              with open(metadata_file, 'r') as f:
                  metadata = json.load(f)
          else:
              metadata = {}

          metadata['last_retest'] = "$TIMESTAMP"
          metadata['retest_run_id'] = "${{ github.run_id }}"

          with open(metadata_file, 'w') as f:
              json.dump(metadata, f, indent=2)

          print(f"✅ Retest metadata updated at $TIMESTAMP")
          EOF

      - name: Commit retest results
        run: |
          git config --local user.name "github-actions[bot]"
          git config --local user.email "github-actions[bot]@users.noreply.github.com"

          git add output/

          if git diff --staged --quiet; then
            echo "ℹ️ No changes from retest"
          else
            git commit -m "🔄 Retest results - $(date -u +'%Y-%m-%d %H:%M:%S UTC')

[skip ci]"
            git push origin main
            echo "✅ Retest results pushed"
          fi